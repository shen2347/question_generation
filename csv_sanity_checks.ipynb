{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../exports/%s/json_format_balanced_combined/test-0-1814.txt' % (d_path), 'rb') as f:\n",
    "    test = json.load(f)\n",
    "    \n",
    "with open('../exports/%s/json_format_balanced_combined/train-0-7787.txt' % (d_path), 'rb') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = {}\n",
    "total.update(train)\n",
    "total.update(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compo = {}\n",
    "test_steps = {}\n",
    "for i in test:\n",
    "    q = test[i]\n",
    "    if q['novel_comp'] == 1:\n",
    "        test_compo[i] = q\n",
    "    if q['more_steps'] == 1:\n",
    "        test_steps[i] = q\n",
    "        \n",
    "train_compo = {}\n",
    "train_steps = {}\n",
    "for i in train:\n",
    "    q = train[i]\n",
    "    if q['novel_comp'] == 0:\n",
    "        train_compo[i] = q\n",
    "    if q['more_steps'] == 0:\n",
    "        train_steps[i] = q\n",
    "        \n",
    "total_compo = {}\n",
    "total_compo.update(train_compo)\n",
    "total_compo.update(test_compo)\n",
    "\n",
    "total_steps = {}\n",
    "total_steps.update(train_steps)\n",
    "total_steps.update(test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] All balanced ids match json ids and vice versa\n",
    "- [x] Everything that is marked compo/steps is in compo/steps and vice versa\n",
    "- [x] Switched to lowercase if do that\n",
    "- [x] No duplicated keys\n",
    "- [x] They are the same size (and the same size as the published numbers in the pdf)\n",
    "- it mat\n",
    "\n",
    "\n",
    "# TODO: check that total is test + val + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSVfinal_csv(x):\n",
    "    train = pd.read_csv('../exports/%s/final_csvs/%s-%s.csv' % (d_path, 'train', x))\n",
    "    val = pd.read_csv('../exports/%s/final_csvs/%s-%s.csv' % (d_path, 'valid', x))\n",
    "    train = pd.concat([train, val])\n",
    "    test = pd.read_csv('../exports/%s/final_csvs/%s-%s.csv' % (d_path, 'test', x))\n",
    "    total = pd.read_csv('../exports/%s/final_csvs/%s-%s.csv' % (d_path, 'total', x))\n",
    "    \n",
    "    return train, test, total\n",
    "\n",
    "\n",
    "def getCSV(x):\n",
    "    if x == 'balanced':\n",
    "        folder = 'balanced'\n",
    "    elif x == 'compo':\n",
    "        folder = 'novel compositions'\n",
    "    elif x == 'steps':\n",
    "        x = 'steps_templ'\n",
    "        folder = 'more compositional steps'\n",
    "    train = pd.read_csv('../ALL FINAL DATA/agqa_2.0/csvs/%s/Train_frameqa_question-%s.csv' % (folder, x))\n",
    "    test = pd.read_csv('../ALL FINAL DATA/agqa_2.0/csvs/%s/Test_frameqa_question-%s.csv' % (folder, x))\n",
    "    total = pd.read_csv('../ALL FINAL DATA/agqa_2.0/csvs/%s/Total_frameqa_question-%s.csv' % (folder, x))\n",
    "\n",
    "    return train, test, total\n",
    "\n",
    "\n",
    "def getTXT(x):\n",
    "    if x == 'balanced':\n",
    "        return train, test, total\n",
    "    elif x == 'compo':\n",
    "        return train_compo, test_compo, total_compo\n",
    "    elif x == 'steps':\n",
    "        return train_steps, test_steps, total_steps\n",
    "    else:\n",
    "        print('invalid type %s' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sameSize(csv, txt):\n",
    "    return csv.shape[0] == len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keysUnique(csv):\n",
    "    keys = list(csv.key.values)\n",
    "    return len(keys) == len(set(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allLower(csv, txt):\n",
    "    answers = set(csv['answer'].values)\n",
    "    for i in answers:\n",
    "        if i != i.lower():\n",
    "            print(\"CSV Uppercase answer: %s\" % i)\n",
    "            return False\n",
    "    \n",
    "    answers = set([txt[i]['answer'] for i in txt])\n",
    "    for ans in answers:\n",
    "        if ans != ans.lower():\n",
    "            print(\"TXT Uppercase answer: %s\" % i)\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keysMatch(csv, txt):\n",
    "    csv_keys = list(csv['key'].values)\n",
    "    txt_keys = list(txt.keys())\n",
    "    \n",
    "    if len(csv_keys) != len(txt_keys):\n",
    "        print(\"ERROR not same size\")\n",
    "        return False\n",
    "    # make sure all in csv are in txt\n",
    "    for k in csv_keys:\n",
    "        if k not in txt_keys:\n",
    "            print('%s not in txt keys' % k)\n",
    "            return False\n",
    "    \n",
    "    # make sure all in txt are in csv\n",
    "    for k in txt_keys:\n",
    "        if k not in csv_keys:\n",
    "            print('%s not in csv keys' % k)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def totalCorresponds(csvs):\n",
    "    train, test, total = csvs\n",
    "    train = list(train['key'].values)\n",
    "    test = list(test['key'].values)\n",
    "    total = list(total['key'].values)\n",
    "    \n",
    "    if (len(train) + len(test)) != len(total):\n",
    "        print(\"Total is not right length\")\n",
    "        return False\n",
    "    \n",
    "    tot_by_v = {}\n",
    "    for i in total:\n",
    "        v = i[:5]\n",
    "        if v not in tot_by_v:\n",
    "            tot_by_v[v] = []\n",
    "        tot_by_v[v].append(i)\n",
    "    \n",
    "    for i in train + test:\n",
    "        v = i[:5]\n",
    "        if i not in tot_by_v[v]:\n",
    "            print(\"key in train not in total: %s\" % i)\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanityCheck(metric):\n",
    "    print(metric)\n",
    "    names = ['train', 'test', 'total']\n",
    "    csvs = getCSV(metric)\n",
    "    txts = getTXT(metric)\n",
    "    \n",
    "    if True:\n",
    "        for name, csv, txt in zip(names, csvs, txts):\n",
    "            print()\n",
    "            print(name)\n",
    "            print(\"%s: Same size\" % sameSize(csv, txt))\n",
    "            print(\"%s: Unique keys\" % keysUnique(csv))\n",
    "            print(\"%s: All Lower\" % allLower(csv, txt))\n",
    "            #print(\"%s: Keys Match\" % keysMatch(csv, txt))\n",
    "        \n",
    "    print(\"%s: Total corresponds\" % totalCorresponds(csvs))\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run under here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "\n",
      "train\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "test\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "total\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "True: Total corresponds\n",
      "compo\n",
      "\n",
      "train\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "test\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "total\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "True: Total corresponds\n",
      "steps\n",
      "\n",
      "train\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "test\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "\n",
      "total\n",
      "True: Same size\n",
      "True: Unique keys\n",
      "True: All Lower\n",
      "True: Total corresponds\n"
     ]
    }
   ],
   "source": [
    "for metric in ['balanced', 'compo', 'steps']: #  \n",
    "    sanityCheck(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492033"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = len(total_steps)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = int(end / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "\n",
    "for i in range(0, end, step):\n",
    "    x.append((i, i + step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 298406),\n",
       " (298406, 596812),\n",
       " (596812, 895218),\n",
       " (895218, 1193624),\n",
       " (1193624, 1492030),\n",
       " (1492030, 1790436)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose(food, Query(class, OnlyItem(IterateUntil(backward, video, Exists(behind, Filter(frame, [relations])), Filter(frame, [relations, behind, objects])))), IterateUntil(forward, video, XOR(Exists(food, Filter(frame, [relations, touching, objects])), Exists(Query(class, OnlyItem(IterateUntil(backward, video, Exists(behind, Filter(frame, [relations])), Filter(frame, [relations, behind, objects])))), Filter(frame, [relations, touching, objects]))), Filter(frame, [relations, touching, objects])))\n"
     ]
    }
   ],
   "source": [
    "for i in train:\n",
    "    q = train[i]\n",
    "    p = q['program']\n",
    "    if 'forward' in p:\n",
    "        print(p)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
